{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RANDOM FOREST AND GBDT ON AMAZON REVIEWS DATASET"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## about dataset:\n",
    "\n",
    "Data Source: https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.<br>\n",
    "\n",
    "Number of reviews: 568,454<br>\n",
    "Number of users: 256,059<br>\n",
    "Number of products: 74,258<br>\n",
    "Timespan: Oct 1999 - Oct 2012<br>\n",
    "Number of Attributes/Columns in data: 10 \n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1- Id<br>\n",
    "2- ProductId - unique identifier for the product<br>\n",
    "3- UserId - unqiue identifier for the user<br>\n",
    "4- ProfileName<br>\n",
    "5- HelpfulnessNumerator - number of users who found the review helpful<br>\n",
    "6- HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not<br>\n",
    "7- Score - rating between 1 and 5<br>\n",
    "8- Time - timestamp for the review<br>\n",
    "9- Summary - brief summary of the review<br>\n",
    "10- Text - text of the review<br>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "con = sqlite3.connect('./amazon-fine-food-reviews/database.sqlite') \n",
    "filtered_data = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3\n",
    "\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4500, 10)\n",
      "(6500, 10)\n"
     ]
    }
   ],
   "source": [
    "s1= filtered_data.loc[filtered_data[\"Score\"]>=4].sample(n=4500,random_state=1)\n",
    "print(s1.shape)\n",
    "\n",
    "s2= filtered_data.loc[filtered_data[\"Score\"]<=2].sample(n=6500,random_state=127)\n",
    "print(s2.shape)\n",
    "data=s1\n",
    "data=data.append(s2)\n",
    "data.shape\n",
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "data['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "negative    5990\n",
       "positive    4434\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data=data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape\n",
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
    "final=final.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\"},keep='first',inplace=False)\n",
    "final.shape\n",
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "okay, it's freeze-dried liver cube-lets.  my common sense tells me that for a lot less than the price of this treat i could buy real liver, cube it and freeze it.  it would serve the same purpose for a lot less money, and it would not be over-processed.<br />that said, our dog would do back flips for this treat, so if you're made of money, go ahead.  you'll make your dog's day  :-)\n",
      "[nltk_data] Error loading stopwords: <urlopen error [Errno 11001]\n",
      "[nltk_data]     getaddrinfo failed>\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "i=0;\n",
    "for sent in final['Text'].values:\n",
    "    if (len(re.findall('<.*?>', sent))):\n",
    "        print(i)\n",
    "        print(sent)\n",
    "        break;\n",
    "    i += 1;    \n",
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "sno = nltk.stem.SnowballStemmer('english') \n",
    "\n",
    "def cleanhtml(sentence): \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): \n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] \n",
    "all_negative_words=[] \n",
    "s=''\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    \n",
    "    sent=cleanhtml(sent) \n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (final['Score'].values)[i] == 'positive': \n",
    "                        all_positive_words.append(s) \n",
    "                    if(final['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s) \n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "\n",
    "    str1 = b\" \".join(filtered_sentence)\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10424, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['CleanedText']=final_string\n",
    "final.head(3) \n",
    "\n",
    "\n",
    "conn = sqlite3.connect('final.sqlite')\n",
    "c=conn.cursor()\n",
    "conn.text_factory = str\n",
    "final.to_sql('Reviews', conn, flavor=None, schema=None, if_exists='replace', index=True, index_label=None, chunksize=None,\n",
    "             dtype=None)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=final.sort_values('Time')\n",
    "x= np.array(final.iloc[:, 0:10])\n",
    "y= np.array(final['Score'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest on Bag of words\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "count_vect = CountVectorizer()\n",
    "final_bow = count_vect.fit_transform(x[:,9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10424, 21944)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_bow.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, X_test, y_1, y_test = cross_validation.train_test_split(final_bow, y, test_size=0.3)\n",
    "\n",
    "X_tr, X_cv, y_tr, y_cv = cross_validation.train_test_split(X_1, y_1, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=10, n_jobs=1,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf = RandomForestClassifier()\n",
    "clf.fit(X_tr,y_tr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy is 74%\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, pred, normalize=True) * float(100)\n",
    "print('\\nCV accuracy is %d%%' %  acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal estimators are 50.\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "baselearners=list(range(10,60,10))\n",
    "for d in baselearners:\n",
    "    clf = RandomForestClassifier(n_estimators=d)\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "optimal_estimators = baselearners[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal estimators are %d.' % optimal_estimators)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test accuracy is 78%\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf = clf.fit(X_tr,y_tr)\n",
    "pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred, normalize=True) * float(100)\n",
    "print('\\ntest accuracy is %d%%' %  acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT on Bag Of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy is 79%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "clf= GradientBoostingClassifier()\n",
    "clf.fit(X_tr,y_tr)\n",
    "pred = clf.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, pred, normalize=True) * float(100)\n",
    "print('\\nCV accuracy is %d%%' %  acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal estimators are 900.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "cv_scores = []\n",
    "lr=[0.1,0.3,0.5,0.7,1.0]\n",
    "baselearners=list(range(100,1000,200))\n",
    "depth=list(range(1,6,1))\n",
    "for bl in baselearners:\n",
    "    clf = GradientBoostingClassifier(n_estimators=bl)\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "optimal_estimators = baselearners[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal estimators are %d.' % optimal_estimators)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal learning rate is 1.\n"
     ]
    }
   ],
   "source": [
    "for l in range(5):\n",
    "    clf = GradientBoostingClassifier(learning_rate=lr[l])\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "optimal_learningrate = lr[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal learning rate is %d.' % optimal_learningrate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal depth is 5.\n"
     ]
    }
   ],
   "source": [
    "for d in depth:\n",
    "    clf = GradientBoostingClassifier(max_depth=d)\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "optimal_depth = depth[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal depth is %d.'% optimal_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test accuracy is 83%\n"
     ]
    }
   ],
   "source": [
    "clf = GradientBoostingClassifier(n_estimators=900,learning_rate=1.0,max_depth=5)\n",
    "clf = clf.fit(X_tr,y_tr)\n",
    "pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred, normalize=True) * float(100)\n",
    "print('\\ntest accuracy is %d%%' %  acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1570,  198],\n",
       "       [ 324, 1036]], dtype=int64)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "- the optimal base learners are 50 and 900 for RF and GBDT respectively.\n",
    "- Based on Accuracy of both CV and Test data GBDT is performing slightly better than RF with Optimal learning rate 1 and depth of 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "final_tf_idf = tf_idf_vect.fit_transform(x[:,9])\n",
    "final_tf_idf.get_shape()\n",
    "X_2, X_test1, y_2, y_test1 = cross_validation.train_test_split(final_tf_idf, y, test_size=0.3)\n",
    "\n",
    "X_tr1, X_cv1, y_tr1, y_cv1 = cross_validation.train_test_split(X_2, y_2, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal estimators are 50.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_scores = []\n",
    "baselearners=list(range(10,60,10))\n",
    "for d in baselearners:\n",
    "    clf = RandomForestClassifier(n_estimators=d)\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "optimal_estimators = baselearners[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal estimators are %d.' % optimal_estimators)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy is 78%\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(X_tr,y_tr)\n",
    "\n",
    "pred = clf.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, pred, normalize=True) * float(100)\n",
    "print('\\nCV accuracy is %d%%' %  acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test accuracy is 79%\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred, normalize=True) * float(100)\n",
    "print('\\ntest accuracy is %d%%' %  acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1670,   98],\n",
       "       [ 539,  821]], dtype=int64)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT on TFIDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal estimators are 900.\n",
      "\n",
      "The optimal learning rate is 1.\n",
      "\n",
      "The optimal depth is 5.\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "lr=[0.1,0.3,0.5,0.7,1.0]\n",
    "baselearners=list(range(100,1000,200))\n",
    "depth=list(range(1,6,1))\n",
    "for bl in baselearners:\n",
    "    clf = GradientBoostingClassifier(n_estimators=bl)\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "optimal_estimators = baselearners[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal estimators are %d.' % optimal_estimators)\n",
    "\n",
    "for l in range(5):\n",
    "    clf = GradientBoostingClassifier(learning_rate=lr[l])\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "optimal_learningrate = lr[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal learning rate is %d.' % optimal_learningrate)\n",
    "\n",
    "for d in depth:\n",
    "    clf = GradientBoostingClassifier(max_depth=d)\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "optimal_depth = depth[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal depth is %d.'% optimal_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy is 83%\n"
     ]
    }
   ],
   "source": [
    "clf= GradientBoostingClassifier(n_estimators=900,learning_rate=1.0,max_depth=5)\n",
    "clf.fit(X_tr,y_tr)\n",
    "pred = clf.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, pred, normalize=True) * float(100)\n",
    "print('\\nCV accuracy is %d%%' %  acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test accuracy is 82%\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(X_test)\n",
    "acc = accuracy_score(y_test, pred, normalize=True) * float(100)\n",
    "print('\\ntest accuracy is %d%%' %  acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1559,  209],\n",
       "       [ 323, 1037]], dtype=int64)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation :\n",
    "- the optimal base learners are 50 and 900 for RF and GBDT respectively.\n",
    "- based on the results the GBDT model is performing good with accuracies of over 80 in both test and Cv data with optimal learning rate of 1.0 and depth of 5."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest on Avg_W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7296\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "X_1, X_test, y_1, y_test = cross_validation.train_test_split(final['Text'], y, test_size=0.3)\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "import gensim\n",
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in X_1.values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent.append(filtered_sentence)\n",
    "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=5,size=50, workers=4)    \n",
    "words = list(w2v_model.wv.vocab)\n",
    "    \n",
    "avg_w2v = [];\n",
    "for sent in list_of_sent:\n",
    "    sent_vec = np.zeros(50) \n",
    "    cnt_words =0; \n",
    "    for word in sent: \n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    avg_w2v.append(sent_vec)\n",
    "print(len(avg_w2v))\n",
    "print(len(avg_w2v[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_tr, X_cv, y_tr, y_cv = cross_validation.train_test_split(avg_w2v, y_1, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal estimators are 50.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_scores = []\n",
    "baselearners=list(range(10,60,10))\n",
    "for d in baselearners:\n",
    "    clf = RandomForestClassifier(n_estimators=d)\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "optimal_estimators = baselearners[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal estimators are %d.' % optimal_estimators)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy is 72%\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=50)\n",
    "clf.fit(X_tr,y_tr)\n",
    "\n",
    "pred = clf.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, pred, normalize=True) * float(100)\n",
    "print('\\nCV accuracy is %d%%' %  acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3128\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in X_test.values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent.append(filtered_sentence)\n",
    "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=5,size=50, workers=4)    \n",
    "words = list(w2v_model.wv.vocab)\n",
    "avg_w2v = [];\n",
    "for sent in list_of_sent:\n",
    "    sent_vec = np.zeros(50) \n",
    "    cnt_words =0; \n",
    "    for word in sent: \n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    avg_w2v.append(sent_vec)\n",
    "print(len(avg_w2v))\n",
    "print(len(avg_w2v[0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test accuracy is 45%\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(avg_w2v)\n",
    "acc = accuracy_score(y_test, pred, normalize=True) * float(100)\n",
    "print('\\ntest accuracy is %d%%' %  acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 419, 1378],\n",
       "       [ 313, 1018]], dtype=int64)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT on Avg_W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal estimators are 300.\n",
      "\n",
      "The optimal learning rate is 0.\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "lr=[0.1,0.3,0.5,0.7,1.0]\n",
    "baselearners=list(range(100,1000,200))\n",
    "depth=list(range(1,6,1))\n",
    "for bl in baselearners:\n",
    "    clf = GradientBoostingClassifier(n_estimators=bl)\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "optimal_estimators = baselearners[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal estimators are %d.' % optimal_estimators)\n",
    "\n",
    "for l in range(5):\n",
    "    clf = GradientBoostingClassifier(learning_rate=lr[l])\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "optimal_learningrate = lr[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal learning rate is %d.' % optimal_learningrate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal depth is 4.\n"
     ]
    }
   ],
   "source": [
    "cv_scores=[]\n",
    "for d in range(1,6):\n",
    "    clf = GradientBoostingClassifier(max_depth=d)\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "optimal_depth = depth[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal depth is %d.'% optimal_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy is 73%\n"
     ]
    }
   ],
   "source": [
    "clf= GradientBoostingClassifier(n_estimators=300,learning_rate=0.1,max_depth=4)\n",
    "clf.fit(X_tr,y_tr)\n",
    "pred = clf.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, pred, normalize=True) * float(100)\n",
    "print('\\nCV accuracy is %d%%' %  acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test accuracy is 49%\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(avg_w2v)\n",
    "acc = accuracy_score(y_test, pred, normalize=True) * float(100)\n",
    "print('\\ntest accuracy is %d%%' %  acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[934, 863],\n",
       "       [726, 605]], dtype=int64)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "- here both the models perform almost same with similar accuracy rates just a little higher in GBDT's Test accuracy.\n",
    "- the optimal estimators are 40,300 for RF and GBDT respectively and GBDT optimal depth as 4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random Forest on TFIDF-W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, X_test, y_1, y_test = cross_validation.train_test_split(x[:,9], y, test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(7296, 223920)\n"
     ]
    }
   ],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "final_tf_idf = tf_idf_vect.fit_transform(X_1)\n",
    "print(final_tf_idf.get_shape())\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7296\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle\n",
    "import gensim\n",
    "\n",
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in X_1:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent.append(filtered_sentence)\n",
    "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=5,size=50, workers=4)    \n",
    "words = list(w2v_model.wv.vocab)\n",
    "avg_w2v = [];\n",
    "for sent in list_of_sent:\n",
    "    sent_vec = np.zeros(50) \n",
    "    cnt_words =0; \n",
    "    for word in sent: \n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    avg_w2v.append(sent_vec)\n",
    "print(len(avg_w2v))\n",
    "print(len(avg_w2v[0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feat = tf_idf_vect.get_feature_names() \n",
    "\n",
    "tfidf_sent_vectors = []; \n",
    "row=0;\n",
    "for sent in list_of_sent: \n",
    "    sent_vec = np.zeros(50) \n",
    "    weight_sum =0;\n",
    "    for word in sent: \n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            tfidf = final_tf_idf[row, tfidf_feat.index(word)]\n",
    "            sent_vec += (vec * tfidf)\n",
    "            weight_sum += tfidf\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors.append(sent_vec)\n",
    "    row += 1\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_tr, X_cv, y_tr, y_cv = cross_validation.train_test_split(tfidf_sent_vectors , y_1 , test_size=0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal estimators are 40.\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cv_scores = []\n",
    "baselearners=list(range(10,60,10))\n",
    "for d in baselearners:\n",
    "    clf = RandomForestClassifier(n_estimators=d)\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "optimal_estimators = baselearners[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal estimators are %d.' % optimal_estimators)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy is 68%\n"
     ]
    }
   ],
   "source": [
    "clf = RandomForestClassifier(n_estimators=40)\n",
    "clf.fit(X_tr,y_tr)\n",
    "\n",
    "pred = clf.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, pred, normalize=True) * float(100)\n",
    "print('\\nCV accuracy is %d%%' %  acc)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3128, 121035)\n",
      "3128\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "final_tf_idf = tf_idf_vect.fit_transform(X_test)\n",
    "print(final_tf_idf.get_shape())\n",
    "\n",
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in X_test:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent.append(filtered_sentence)\n",
    "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=5,size=50, workers=4)    \n",
    "words = list(w2v_model.wv.vocab)\n",
    "avg_w2v = [];\n",
    "for sent in list_of_sent:\n",
    "    sent_vec = np.zeros(50) \n",
    "    cnt_words =0; \n",
    "    for word in sent: \n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    avg_w2v.append(sent_vec)\n",
    "print(len(avg_w2v))\n",
    "print(len(avg_w2v[0]))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_feat = tf_idf_vect.get_feature_names() \n",
    "\n",
    "tfidf_sent_vectors = []; \n",
    "row=0;\n",
    "for sent in list_of_sent: \n",
    "    sent_vec = np.zeros(50) \n",
    "    weight_sum =0;\n",
    "    for word in sent: \n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            tfidf = final_tf_idf[row, tfidf_feat.index(word)]\n",
    "            sent_vec += (vec * tfidf)\n",
    "            weight_sum += tfidf\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors.append(sent_vec)\n",
    "    row += 1\n",
    "     \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test accuracy is 49%\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(tfidf_sent_vectors)\n",
    "acc = accuracy_score(y_test, pred, normalize=True) * float(100)\n",
    "print('\\ntest accuracy is %d%%' %  acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[820, 976],\n",
       "       [616, 716]], dtype=int64)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT on TFIDF-W2V"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal estimators are 300.\n",
      "\n",
      "The optimal learning rate is 0.\n"
     ]
    }
   ],
   "source": [
    "cv_scores = []\n",
    "lr=[0.1,0.3,0.5,0.7,1.0]\n",
    "baselearners=list(range(100,1000,200))\n",
    "depth=list(range(1,6,1))\n",
    "for bl in baselearners:\n",
    "    clf = GradientBoostingClassifier(n_estimators=bl)\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "optimal_estimators = baselearners[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal estimators are %d.' % optimal_estimators)\n",
    "\n",
    "for l in range(5):\n",
    "    clf = GradientBoostingClassifier(learning_rate=lr[l])\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "\n",
    "optimal_learningrate = lr[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal learning rate is %d.' % optimal_learningrate)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3\n"
     ]
    }
   ],
   "source": [
    "print(optimal_learningrate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The optimal depth is 5.\n"
     ]
    }
   ],
   "source": [
    "cv_scores=[]\n",
    "for d in range(1,6):\n",
    "    clf = GradientBoostingClassifier(max_depth=d)\n",
    "    scores = cross_val_score(clf, X_tr, y_tr, cv=10, scoring='accuracy')\n",
    "    cv_scores.append(scores.mean())\n",
    "MSE = [1 - x for x in cv_scores]\n",
    "optimal_depth = depth[MSE.index(min(MSE))]\n",
    "print('\\nThe optimal depth is %d.'% optimal_depth)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy is 69%\n"
     ]
    }
   ],
   "source": [
    "clf= GradientBoostingClassifier(n_estimators=300,learning_rate=0.3,max_depth=5)\n",
    "clf.fit(X_tr,y_tr)\n",
    "pred = clf.predict(X_cv)\n",
    "acc = accuracy_score(y_cv, pred, normalize=True) * float(100)\n",
    "print('\\nCV accuracy is %d%%' %  acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "test accuracy is 52%\n"
     ]
    }
   ],
   "source": [
    "pred = clf.predict(tfidf_sent_vectors)\n",
    "acc = accuracy_score(y_test, pred, normalize=True) * float(100)\n",
    "print('\\ntest accuracy is %d%%' %  acc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1085,  711],\n",
       "       [ 789,  543]], dtype=int64)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "- as seen above the optimal estimators or base learners are 40 and 300 for Random Forest and GBDT respectively.\n",
    "- as compared with accuracies of both models the performance are almost identical with GBDT's Test accuracy just a little higher than random forest."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RANDOM_FOREST:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------+-------------+---------------+\n",
      "| VECTORIZER | Optimal BaseLearners | CV-accuracy | Test Accuracy |\n",
      "+------------+----------------------+-------------+---------------+\n",
      "|    BOW     |          50          |      74     |       78      |\n",
      "|   TFIDF    |          50          |      78     |       79      |\n",
      "|  AVG-W2V   |          50          |      72     |       45      |\n",
      "| TFIDF-W2V  |          40          |      68     |       49      |\n",
      "+------------+----------------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "from ipywidgets import *\n",
    "from prettytable import PrettyTable\n",
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"VECTORIZER\", \"Optimal BaseLearners\", \"CV-accuracy\", \"Test Accuracy\"]\n",
    "\n",
    "x.add_row([\"BOW\", 50, 74, 78])\n",
    "x.add_row([\"TFIDF\", 50, 78, 79])\n",
    "x.add_row([\"AVG-W2V\", 50, 72, 45])\n",
    "x.add_row([\"TFIDF-W2V\", 40, 68, 49])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GBDT:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------+----------------------+----------------------+---------------+-------------+---------------+\n",
      "| VECTORIZER | Optimal BaseLearners | Optimal learningrate | Optimal depth | CV-accuracy | Test Accuracy |\n",
      "+------------+----------------------+----------------------+---------------+-------------+---------------+\n",
      "|    BOW     |         900          |          1           |       5       |      79     |       83      |\n",
      "|   TFIDF    |         900          |          1           |       5       |      83     |       82      |\n",
      "|  AVG-W2V   |         300          |         0.1          |       4       |      73     |       49      |\n",
      "| TFIDF-W2V  |         300          |         0.3          |       5       |      69     |       52      |\n",
      "+------------+----------------------+----------------------+---------------+-------------+---------------+\n"
     ]
    }
   ],
   "source": [
    "x = PrettyTable()\n",
    "\n",
    "x.field_names = [\"VECTORIZER\", \"Optimal BaseLearners\", \"Optimal learningrate\", \"Optimal depth\", \"CV-accuracy\", \"Test Accuracy\"]\n",
    "\n",
    "x.add_row([\"BOW\", 900, 1, 5, 79, 83])\n",
    "x.add_row([\"TFIDF\", 900, 1, 5, 83, 82])\n",
    "x.add_row([\"AVG-W2V\", 300, 0.1, 4, 73, 49])\n",
    "x.add_row([\"TFIDF-W2V\", 300, 0.3, 5, 69, 52])\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Key points:\n",
    "- From the above results and Tables above we can state that our GBDT is performing better than RF model on the taken data sample.\n",
    "- Overall from the taken dataset the Tfidf_GBDT model is performing better than other models and vectorizers combination.\n",
    "- This may be true only in my case beacuse I have taken a sample of the reviews dataset so These conclusions are based on my sample dataset."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
