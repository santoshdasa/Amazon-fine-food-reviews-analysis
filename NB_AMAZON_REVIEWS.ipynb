{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Amazon Fine Food Reviews Naive Bayes\n",
    "\n",
    "\n",
    "Data Source: https://www.kaggle.com/snap/amazon-fine-food-reviews\n",
    "\n",
    "The Amazon Fine Food Reviews dataset consists of reviews of fine foods from Amazon.<br>\n",
    "\n",
    "Number of reviews: 568,454<br>\n",
    "Number of users: 256,059<br>\n",
    "Number of products: 74,258<br>\n",
    "Timespan: Oct 1999 - Oct 2012<br>\n",
    "Number of Attributes/Columns in data: 10 \n",
    "\n",
    "Attribute Information:\n",
    "\n",
    "1. Id\n",
    "2. ProductId - unique identifier for the product\n",
    "3. UserId - unqiue identifier for the user\n",
    "4. ProfileName\n",
    "5. HelpfulnessNumerator - number of users who found the review helpful\n",
    "6. HelpfulnessDenominator - number of users who indicated whether they found the review helpful or not\n",
    "7. Score - rating between 1 and 5\n",
    "8. Time - timestamp for the review\n",
    "9. Summary - brief summary of the review\n",
    "10. Text - text of the review\n",
    "\n",
    "\n",
    "#### Objective:\n",
    "Given a review, determine whether the review is positive (Rating of 4 or 5) or negative (rating of 1 or 2).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " In Naive bayes we assume conditional independency as our key assumption.This is a 2 class classification problem \n",
    " where class 1 resemble the review as positive and class 0 as the negative review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "con = sqlite3.connect('./amazon-fine-food-reviews/database.sqlite') \n",
    "filtered_data = pd.read_sql_query(\"\"\"\n",
    "SELECT *\n",
    "FROM Reviews\n",
    "WHERE Score != 3\n",
    "\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20000, 10)\n",
      "(20000, 10)\n"
     ]
    }
   ],
   "source": [
    "s1= filtered_data.loc[filtered_data[\"Score\"]>=4].sample(n=20000,random_state=1)\n",
    "print(s1.shape)\n",
    "\n",
    "s2= filtered_data.loc[filtered_data[\"Score\"]<=2].sample(n=20000,random_state=127)\n",
    "print(s2.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(40000, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data=s1\n",
    "data=data.append(s2)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def partition(x):\n",
    "    if x < 3:\n",
    "        return 'negative'\n",
    "    return 'positive'\n",
    "\n",
    "actualScore = filtered_data['Score']\n",
    "positiveNegative = actualScore.map(partition) \n",
    "data['Score'] = positiveNegative"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(36108, 10)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sorted_data=data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\n",
    "final=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35554, 10)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n",
    "final=final.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\"},keep='first',inplace=False)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "positive    18914\n",
       "negative    16640\n",
       "Name: Score, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['Score'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DATA pre-processing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n",
      "Summary:  A young boy describes the usefulness of chicken soup with rice for each month of the year.<br /><br />Evaluation:  With Sendak's creative repetitious and rhythmic words, children will enjoy and learn to read the story of a boy who loves chicken soup with rice!  Through Sendak's catchy story, children will also learn the months of the year, as well as what seasons go with what month! They learn to identify ice-skating and snowmen in the winter; strong wind in March; birds and flowers in the spring; swimming and hot temperatures in the summer; and finally different holidays throughout the year. Such as Halloween in October, and Christmas in December.<br /><br />Sendak's simple three colored crayon-like drawings are a perfect addition to his educational and entertaining story.<br /><br />A great activity that you can do with this book is to have children draw their own illustrations for each month of the year.  Afterwards you can bind the pages together so the children can create their own book.\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "i=0;\n",
    "for sent in final['Text'].values:\n",
    "    if (len(re.findall('<.*?>', sent))):\n",
    "        print(i)\n",
    "        print(sent)\n",
    "        break;\n",
    "    i += 1;    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\santosh\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "{'this', 's', \"couldn't\", 'shan', 'hadn', 'that', 'whom', 'my', 'itself', 'mustn', 'does', 'yourselves', 'her', 'having', 'shouldn', 'these', 'mightn', 'such', 'no', 'of', 'you', 'which', \"won't\", 'it', \"needn't\", \"doesn't\", 'after', 'in', \"isn't\", 'was', 'between', 'why', \"should've\", 'had', 'their', 'some', 'being', \"mightn't\", 'him', 'few', 'are', 'o', 'not', 'but', 'herself', 'haven', 'just', 'for', 'am', 'most', \"haven't\", 'how', 'is', 'they', 'from', 'ours', 'on', 'when', 't', 'can', 're', 'both', 'didn', 'those', 'while', 'nor', 'then', 'has', \"you're\", 'wouldn', 'to', 'as', 'aren', 'and', 'so', 'hers', 'each', 'doesn', 'himself', 'with', 'yourself', \"hasn't\", \"weren't\", 'off', 'i', 'we', 'than', 'any', 'until', 'theirs', \"you'd\", 'should', 'where', 'needn', 'there', 'couldn', 'through', 'during', \"it's\", 'only', 'over', 've', \"hadn't\", 'above', 'again', 'me', 'own', 'themselves', \"you'll\", 'do', 'yours', 'below', 'what', 'will', 'been', 'be', 'into', 'them', 'all', 'doing', 'further', 'if', 'isn', 'down', 'ain', 'weren', 'a', 'were', 'because', \"aren't\", 'about', \"wouldn't\", 'before', 'under', 'once', 'll', 'your', 'out', \"don't\", 'he', 'his', 'against', \"shan't\", 'or', \"didn't\", 'ma', 'y', 'have', 'same', 'too', 'did', 'm', 'wasn', 'an', 'myself', 'very', 'd', 'hasn', \"that'll\", \"mustn't\", \"you've\", 'by', 'other', 'our', \"she's\", \"shouldn't\", 'more', 'she', 'at', 'won', 'up', 'its', 'here', \"wasn't\", 'now', 'ourselves', 'don', 'the', 'who'}\n",
      "tasti\n"
     ]
    }
   ],
   "source": [
    "import string\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "\n",
    "stop = set(stopwords.words('english'))\n",
    "sno = nltk.stem.SnowballStemmer('english') \n",
    "\n",
    "def cleanhtml(sentence): \n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): \n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned\n",
    "print(stop)\n",
    "print(sno.stem('tasty'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "all_positive_words=[] \n",
    "all_negative_words=[] \n",
    "s=''\n",
    "for sent in final['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    \n",
    "    sent=cleanhtml(sent) \n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    if (final['Score'].values)[i] == 'positive': \n",
    "                        all_positive_words.append(s) \n",
    "                    if(final['Score'].values)[i] == 'negative':\n",
    "                        all_negative_words.append(s) \n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "\n",
    "    str1 = b\" \".join(filtered_sentence)\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35554, 11)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final['CleanedText']=final_string\n",
    "final.head(3) \n",
    "\n",
    "\n",
    "conn = sqlite3.connect('final.sqlite')\n",
    "c=conn.cursor()\n",
    "conn.text_factory = str\n",
    "final.to_sql('Reviews', conn, flavor=None, schema=None, if_exists='replace', index=True, index_label=None, chunksize=None,\n",
    "             dtype=None)\n",
    "final.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Time based sorting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "final=final.sort_values('Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "x= np.array(final.iloc[:, 0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "y= np.array(final['Score'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## bag of words-Naive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vect = CountVectorizer()\n",
    "final_bow = count_vect.fit_transform(x[:,9])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35554, 38046)"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_bow.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "y[y=='positive']=1\n",
    "y[y==\"negative\"]=0\n",
    "y=y.astype('int')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santosh\\Anaconda3\\lib\\site-packages\\sklearn\\cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.cross_validation import train_test_split\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.cross_validation import cross_val_score\n",
    "from collections import Counter\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn import cross_validation\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_1, X_test, y_1, y_test = cross_validation.train_test_split(final_bow, y, test_size=0.3)\n",
    "\n",
    "X_tr, X_cv, y_tr, y_cv = cross_validation.train_test_split(X_1, y_1, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy for alpha=0.001000 is 81%\n",
      "\n",
      "CV accuracy for alpha=0.010000 is 83%\n",
      "\n",
      "CV accuracy for alpha=0.100000 is 84%\n",
      "\n",
      "CV accuracy for alpha=0.000000 is 78%\n",
      "\n",
      "CV accuracy for alpha=1.000000 is 85%\n",
      "\n",
      "CV accuracy for alpha=10.000000 is 85%\n",
      "\n",
      "CV accuracy for alpha=100.000000 is 81%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santosh\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "n=0\n",
    "while(n<7):\n",
    "    a=[0.001,0.01,0.1,0,1,10,100]\n",
    "    gnb = MultinomialNB(alpha=a[n])\n",
    "    y_pred = gnb.fit(X_tr,y_tr)\n",
    "    pred = gnb.predict(X_cv)\n",
    "    acc = accuracy_score(y_cv, pred, normalize=True) * float(100)\n",
    "    print('\\nCV accuracy for alpha=%f is %d%%' %(float(a[n]),acc))    \n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 85.94731414643293\n",
      "precision score is  86.27476642465228\n",
      "recall score is  85.7305382168692\n",
      "f1 score is  85.94731414643293\n"
     ]
    }
   ],
   "source": [
    "gnb = MultinomialNB(alpha=10)\n",
    "gnb.fit(X_tr,y_tr)\n",
    "pred = gnb.predict(X_test)\n",
    "pre=precision_score(y_test,pred, average='macro')* float(100)\n",
    "acc = accuracy_score(y_test, pred, normalize=True) * float(100)\n",
    "re=recall_score(y_test, pred, average='macro')*float(100)\n",
    "f1=f1_score(y_test, pred, average='micro')* float(100)\n",
    "print(\"accuracy is\",acc)\n",
    "print(\"precision score is \",pre)\n",
    "print(\"recall score is \",re)\n",
    "print(\"f1 score is \",f1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4120,  979],\n",
       "       [ 520, 5048]], dtype=int64)"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test,pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## observation:\n",
    "- the optimal alpha value is 1 and 10 which has 85% accuracy on CV.\n",
    "- with aplha = 10 on test data the metrics are as follows\n",
    "  - accuracy is 85.94%\n",
    "  - precision score is 86.27%\n",
    "  - recall score is 85.73%\n",
    "  - f1 score is 85.94%\n",
    "- confusion matrix values:\n",
    "  - TN is 4120\n",
    "  - FN is 979\n",
    "  - FP is 520\n",
    "  - TP is 5048"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## feature importance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "acc=[]\n",
    "for i in range(38046):\n",
    "    X_1, X_test, y_1, y_test = cross_validation.train_test_split(final_bow[:,i], y, test_size=0.3)\n",
    "    X_tr, X_cv, y_tr, y_cv = cross_validation.train_test_split(X_1, y_1, test_size=0.3)\n",
    "    gnb = MultinomialNB()\n",
    "    y_pred = gnb.fit(X_tr,y_tr)\n",
    "    pred = gnb.predict(X_cv)\n",
    "    gnb = MultinomialNB(alpha=10)\n",
    "    gnb.fit(X_tr,y_tr)\n",
    "    pred = gnb.predict(X_test)\n",
    "    acc = accuracy_score(y_test, pred, normalize=True) * float(100)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "53.12646479797506\n"
     ]
    }
   ],
   "source": [
    "acc=np.array(acc)\n",
    "print(acc.max())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## tfidf NaiveBayes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(35554, 660649)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_vect = TfidfVectorizer(ngram_range=(1,2))\n",
    "final_tf_idf = tf_idf_vect.fit_transform(x[:,9])\n",
    "final_tf_idf.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_2, X_test1, y_2, y_test1 = cross_validation.train_test_split(final_tf_idf, y, test_size=0.3)\n",
    "\n",
    "X_tr1, X_cv1, y_tr1, y_cv1 = cross_validation.train_test_split(X_2, y_2, test_size=0.3)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy for alpha=0.000100 is 83%\n",
      "\n",
      "CV accuracy for alpha=0.001000 is 85%\n",
      "\n",
      "CV accuracy for alpha=0.010000 is 87%\n",
      "\n",
      "CV accuracy for alpha=0.100000 is 89%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\santosh\\Anaconda3\\lib\\site-packages\\sklearn\\naive_bayes.py:472: UserWarning: alpha too small will result in numeric errors, setting alpha = 1.0e-10\n",
      "  'setting alpha = %.1e' % _ALPHA_MIN)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "CV accuracy for alpha=0.000000 is 78%\n",
      "\n",
      "CV accuracy for alpha=1.000000 is 85%\n",
      "\n",
      "CV accuracy for alpha=10.000000 is 73%\n",
      "\n",
      "CV accuracy for alpha=100.000000 is 53%\n",
      "\n",
      "CV accuracy for alpha=1000.000000 is 52%\n"
     ]
    }
   ],
   "source": [
    "\n",
    "n=0\n",
    "while(n<9):\n",
    "    a=[0.0001,0.001,0.01,0.1,0,1,10,100,1000]\n",
    "    gnb = MultinomialNB(alpha=a[n])\n",
    "    y_pred1 = gnb.fit(X_tr1,y_tr1)\n",
    "    pred1 = gnb.predict(X_cv1)\n",
    "    acc1 = accuracy_score(y_cv1, pred1, normalize=True) * float(100)\n",
    "    print('\\nCV accuracy for alpha=%f is %d%%' %(float(a[n]),acc1))    \n",
    "    n=n+1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy is 88.95659510640293\n",
      "precision score is  87.91485082132083\n",
      "recall score is  91.98526832690284\n",
      "f1 score is  89.90401097017484\n"
     ]
    }
   ],
   "source": [
    "gnb = MultinomialNB(alpha=0.1)\n",
    "gnb.fit(X_tr1,y_tr1)\n",
    "pred1 = gnb.predict(X_test1)\n",
    "pre2=precision_score(y_test1,pred1)* float(100)\n",
    "acc2 = accuracy_score(y_test1, pred1, normalize=True) * float(100)\n",
    "re2=recall_score(y_test1, pred1)*float(100)\n",
    "f12=f1_score(y_test1, pred1)* float(100)\n",
    "print(\"accuracy is\",acc2)\n",
    "print(\"precision score is \",pre2)\n",
    "print(\"recall score is \",re2)\n",
    "print(\"f1 score is \",f12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[4244,  721],\n",
       "       [ 457, 5245]], dtype=int64)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "confusion_matrix(y_test1,pred1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Observation:\n",
    "- the optimal alpha value is 0.1 on cv data with accuracy of 89%.\n",
    "- the metrics for test data are as follows\n",
    "  - accuracy is 88.9%\n",
    "  - precison score is 87.91%\n",
    "  - recall score is 91.98%\n",
    "  - f1 score is 89.90%\n",
    "- the confusion matrix values are :\n",
    "  - TN: 4244\n",
    "  - FN: 721\n",
    "  - FP: 457\n",
    "  - TP: 5245"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CONCLUSION: "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Here we find that the feature with highest importance is giving us 53% accuracy\n",
    "- we also find that in both the bag of words and tfidf naive bayes models the accuracy on test data is 85% and 88%\n",
    " respectively.\n",
    "- as we know from the confusion matrix the true positive and true negative values must be high.\n",
    "- the same high TN and TP we observe in the models outcomes.\n",
    "- the values from the bag of words NB are:\n",
    "  - accuracy is 85.94%\n",
    "  - precision score is 86.27%\n",
    "  - recall score is 85.73%\n",
    "  - f1 score is 85.94%\n",
    "- confusion matrix values:\n",
    "  - TN is 4120\n",
    "  - FN is 979\n",
    "  - FP is 520\n",
    "  - TP is 5048\n",
    "- the values from tfidf are:\n",
    "  - accuracy is 88.9%\n",
    "  - precison score is 87.91%\n",
    "  - recall score is 91.98%\n",
    "  - f1 score is 89.90%\n",
    "- the confusion matrix values are :\n",
    "  - TN: 4244\n",
    "  - FN: 721\n",
    "  - FP: 457\n",
    "  - TP: 5245\n",
    "- these values are taken from the test data analysis.\n",
    "- I took 40000 data points and I could clearly see that it works better than KNN algorithm.\n",
    "- I can conclude that Naive Bayes is better than KNN in case text data classification.(As we use reviews here)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
